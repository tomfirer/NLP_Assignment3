{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvbT+zJuSvHTsYMLLWCLjY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomfirer/NLP_Assignment3/blob/main/NLP_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOiQNgR7JDZc",
        "outputId": "01a44d62-c950-4c19-f4ad-ea01ab1cf450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### functions ###\n",
        "def clean_text(corpus: list[str]) -> list[str]:\n",
        "  new_corpus = []\n",
        "  for document in corpus:\n",
        "    document = re.sub(r'[^\\w\\s]', '', document)\n",
        "    document = document.lower()\n",
        "    new_corpus.append(document)\n",
        "  return new_corpus\n",
        "\n",
        "\n",
        "def tokenize_nltk(corpus: list[str]) -> list[list[str]]:\n",
        "  token_mat = []\n",
        "  for document in corpus:\n",
        "    token_mat.append(nltk.word_tokenize(document))\n",
        "  return token_mat\n",
        "\n",
        "\n",
        "def remove_stopwords(token_mat: list[list[str]]) -> list[list[str]]:\n",
        "  stop_words = stopwords.words('english')\n",
        "  filtered_tokens = [[token for token in token_arr if token not in stop_words and token.isalpha()] for token_arr in token_mat]\n",
        "  return filtered_tokens\n",
        "\n",
        "\n",
        "def lemmatize_nltk(token_mat: list[list[str]]) -> list[list[str]]:\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  lemmatized_res = []\n",
        "  for token_arr in token_mat:\n",
        "    lemmatized_res.append([lemmatizer.lemmatize(token) for token in token_arr])\n",
        "  return lemmatized_res\n",
        "\n",
        "\n",
        "#\"untokenizes\" a matrix of tokens back into an array of strings\n",
        "def token_matrix_to_string_array(token_mat: list[list[str]]) -> list[str]:\n",
        "  return [' '.join([str(x) for x in token_arr]) for token_arr in token_mat]\n",
        "\n",
        "\n",
        "def get_word2vec_model(token_mat: list[list[str]], vector_size: int) -> Word2Vec:\n",
        "  model = Word2Vec(\n",
        "    sentences=token_mat,      # The corpus to train the model on\n",
        "    vector_size=vector_size,  # The size of the word vectors to be learned\n",
        "    window=5,                 # The size of the window of words to be considered\n",
        "    min_count=5,              # The minimum frequency required for a word to be included in the vocabulary\n",
        "    sg=0,                     # 0 for CBOW, 1 for skip-gram\n",
        "    negative=5,               # The number of negative samples to use for negative sampling\n",
        "    ns_exponent=0.75,         # The exponent used to shape the negative sampling distribution\n",
        "    alpha=0.03,               # The initial learning rate\n",
        "    min_alpha=0.0007,         # The minimum learning rate to which the learning rate will be linearly reduced\n",
        "    epochs=30,                # The number of epochs (iterations) over the corpus\n",
        "    workers=4,                # The number of worker threads to use for training the model\n",
        "    seed=42,                  # The seed for the random number generator\n",
        "    max_vocab_size=None       # The maximum vocabulary size (None means no limit)\n",
        "  )\n",
        "  return model\n",
        "\n",
        "\n",
        "def get_recurrent_model(model_type: str, unit_num: int, vocab_size: int, vector_size: int, max_length: int, embedding_matrix: list[list[float]]) -> Sequential:\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=vector_size, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "  if model_type == 'LSTM':\n",
        "    model.add(LSTM(unit_num))\n",
        "  elif model_type == 'RNN':\n",
        "    model.add(SimpleRNN(unit_num))\n",
        "  else:\n",
        "    return None\n",
        "  model.add(Dense(vocab_size, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "\n",
        "# Predict the next word\n",
        "def predict_next_word(model: Sequential, tokenizer: Tokenizer, text: str, max_sequence_length: int) -> str:\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='pre')\n",
        "    predicted_probabilities = model.predict(sequence)\n",
        "    predicted_word_index = np.argmax(predicted_probabilities, axis=-1)\n",
        "    predicted_word = tokenizer.index_word.get(predicted_word_index[0], 'Unknown')\n",
        "    return predicted_word\n",
        "\n",
        "\n",
        "def generate_completion(model: GPT2LMHeadModel, tokenizer: GPT2Tokenizer, sentence: str, max_length=30) -> str:\n",
        "    #encode input\n",
        "    inputs = tokenizer.encode(sentence, return_tensors='pt')\n",
        "    #generate completion\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    #decode the generated text\n",
        "    completion = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return completion\n",
        "\n",
        "\n",
        "def predict_sentiment(sentence: str, tokenizer: Tokenizer, model: Sequential, maxlen: int, label_encoder: LabelEncoder):\n",
        "    tokens = tokenizer.texts_to_sequences([sentence])\n",
        "    tokens_padded = pad_sequences(tokens, maxlen=maxlen)\n",
        "    #predict\n",
        "    prediction = model.predict(tokens_padded)\n",
        "    sentiment_idx = np.argmax(prediction)\n",
        "    sentiment = label_encoder.inverse_transform([sentiment_idx])[0]\n",
        "\n",
        "    return sentiment, prediction[0][sentiment_idx]"
      ],
      "metadata": {
        "id": "SNRNZynvKXo5"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages_df = pd.read_excel('office_messages.xlsx')\n",
        "messages_df['Messages'] = clean_text(messages_df['Messages'])\n",
        "messages_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3t1Q4yb3JwXa",
        "outputId": "05c251b6-80b6-496c-f3d2-4f7d5139aaa2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Messages Sentiment\n",
              "0  hey team quick reminder todays meeting is at 1...  Positive\n",
              "1  does anyone have the latest sales report need ...  Positive\n",
              "2    happy friday everyone any plans for the weekend  Positive\n",
              "3  congrats to the marketing team for the success...  Positive\n",
              "4  happy birthday to sarah from hr cake in the br...  Positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a37322a7-6d6c-43c6-a1be-513141f881f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Messages</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hey team quick reminder todays meeting is at 1...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>does anyone have the latest sales report need ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>happy friday everyone any plans for the weekend</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>congrats to the marketing team for the success...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>happy birthday to sarah from hr cake in the br...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a37322a7-6d6c-43c6-a1be-513141f881f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a37322a7-6d6c-43c6-a1be-513141f881f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a37322a7-6d6c-43c6-a1be-513141f881f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e1b9ae1-abfb-4395-b06f-41663277e97a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e1b9ae1-abfb-4395-b06f-41663277e97a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e1b9ae1-abfb-4395-b06f-41663277e97a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "messages_df",
              "summary": "{\n  \"name\": \"messages_df\",\n  \"rows\": 224,\n  \"fields\": [\n    {\n      \"column\": \"Messages\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 164,\n        \"samples\": [\n          \"the offices pest control service will be conducted this weekend\",\n          \"there have been reports of phishing emails please be cautious\",\n          \"there have been reports of unauthorized access attempts change your passwords\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Positive\",\n          \"Negative\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Preprocessing ###\n",
        "token_matrix = tokenize_nltk(messages_df['Messages'])\n",
        "token_matrix = remove_stopwords(token_matrix)\n",
        "token_matrix = lemmatize_nltk(token_matrix)\n",
        "print(token_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f383W1q-MNbg",
        "outputId": "5992eac0-8fcf-41e7-8f0f-0f37208d3e9d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['hey', 'team', 'quick', 'reminder', 'today', 'meeting', 'conference', 'room'], ['anyone', 'latest', 'sale', 'report', 'need', 'presentation'], ['happy', 'friday', 'everyone', 'plan', 'weekend'], ['congrats', 'marketing', 'team', 'successful', 'campaign', 'launch'], ['happy', 'birthday', 'sarah', 'hr', 'cake', 'break', 'room', 'pm'], ['got', 'call', 'client', 'loved', 'proposal'], ['weather', 'update', 'snow', 'expected', 'tomorrow', 'morning', 'plan', 'commute', 'accordingly'], ['kudos', 'team', 'fixing', 'server', 'issue', 'quickly'], ['reminder', 'team', 'lunch', 'noon', 'going', 'new', 'place', 'downtown'], ['ceo', 'visiting', 'office', 'next', 'week', 'let', 'ensure', 'everything', 'ready'], ['quick', 'poll', 'team', 'lunch', 'option', 'friday', 'mexican', 'italian'], ['hr', 'update', 'new', 'health', 'insurance', 'option', 'available', 'starting', 'next', 'month'], ['congratulation', 'john', 'promotion', 'senior', 'analyst'], ['team', 'let', 'brainstorm', 'idea', 'upcoming', 'product', 'launch'], ['congrats', 'intern', 'final', 'presentation', 'well', 'done'], ['request', 'feedback', 'new', 'cafeteria', 'menu', 'option'], ['finance', 'team', 'need', 'expense', 'receipt', 'audit', 'submit', 'friday'], ['team', 'building', 'activity', 'park', 'saturday', 'dont', 'forget', 'comfortable', 'shoe'], ['sent', 'agenda', 'next', 'week', 'team', 'meeting', 'check', 'inbox'], ['congrats', 'lisa', 'completing', 'project', 'ahead', 'schedule'], ['office', 'recycling', 'program', 'start', 'next', 'week', 'look', 'bin', 'floor'], ['looking', 'volunteer', 'join', 'office', 'softball', 'team', 'interested'], ['congratulation', 'team', 'achieving', 'uptime', 'last', 'month'], ['reminder', 'flu', 'shot', 'available', 'break', 'room', 'today', 'pm', 'pm'], ['congrats', 'accounting', 'team', 'closing', 'book', 'ahead', 'schedule'], ['reminder', 'companywide', 'town', 'hall', 'meeting', 'next', 'tuesday', 'submit', 'question', 'advance'], ['hr', 'update', 'wellness', 'program', 'launch', 'next', 'week', 'look', 'signup', 'detail'], ['need', 'volunteer', 'holiday', 'decorating', 'committee', 'meeting', 'break', 'room', 'pm', 'today'], ['reminder', 'submit', 'expense', 'report', 'end', 'day'], ['congrats', 'new', 'hire', 'completing', 'first', 'month'], ['reminder', 'submit', 'project', 'update', 'end', 'day'], ['fantastic', 'job', 'presentation', 'team', 'client', 'impressed'], ['happy', 'anniversary', 'company', 'let', 'celebrate', 'cake', 'break', 'room'], ['great', 'news', 'weve', 'secured', 'new', 'client', 'contract'], ['team', 'outing', 'next', 'friday', 'dont', 'forget', 'rsvp'], ['awesome', 'work', 'latest', 'project', 'everyone'], ['new', 'office', 'chair', 'arrived', 'set', 'today'], ['thank', 'hard', 'work', 'quarter', 'bonus', 'distributed', 'next', 'week'], ['let', 'welcome', 'new', 'team', 'member', 'lunch', 'tomorrow'], ['updated', 'health', 'benefit', 'package', 'available', 'check', 'email', 'detail'], ['fantastic', 'feedback', 'last', 'training', 'session', 'well', 'done', 'team'], ['new', 'coffee', 'machine', 'running', 'break', 'room'], ['reminder', 'yoga', 'class', 'conference', 'room', 'pm'], ['team', 'weve', 'reached', 'quarterly', 'goal', 'ahead', 'schedule'], ['office', 'renovation', 'complete', 'enjoy', 'new', 'space'], ['great', 'job', 'recent', 'audit', 'everything', 'order'], ['thank', 'participation', 'charity', 'event', 'raised', 'significant', 'amount'], ['client', 'sent', 'positive', 'feedback', 'recent', 'work'], ['dont', 'forget', 'check', 'new', 'gym', 'facility', 'building'], ['congrats', 'everyone', 'successful', 'quarter'], ['weve', 'got', 'new', 'project', 'starting', 'next', 'week', 'exciting', 'time', 'ahead'], ['office', 'party', 'tonight', 'hope', 'see'], ['congratulation', 'sale', 'team', 'hitting', 'target'], ['let', 'celebrate', 'project', 'success', 'team', 'dinner'], ['new', 'software', 'update', 'rolled', 'check', 'computer'], ['reminder', 'teambuilding', 'event', 'weekend', 'dont', 'miss'], ['great', 'turnout', 'volunteer', 'event', 'thanks', 'participated'], ['new', 'training', 'program', 'well', 'received'], ['well', 'done', 'customer', 'satisfaction', 'survey', 'result'], ['team', 'lunch', 'wednesday', 'celebrate', 'recent', 'success'], ['congratulation', 'design', 'team', 'awardwinning', 'project'], ['new', 'parking', 'policy', 'start', 'next', 'week', 'check', 'email', 'detail'], ['excellent', 'work', 'recent', 'campaign', 'marketing', 'team'], ['team', 'new', 'client', 'joining', 'u', 'next', 'month'], ['great', 'job', 'product', 'launch', 'sale', 'roof'], ['office', 'garden', 'looking', 'great', 'thanks', 'volunteer'], ['reminder', 'endofyear', 'party', 'planning', 'meeting', 'tomorrow'], ['social', 'medium', 'engagement', 'increased', 'significantly', 'well', 'done', 'team'], ['fantastic', 'feedback', 'board', 'meeting', 'keep', 'great', 'work'], ['new', 'intern', 'program', 'start', 'next', 'week', 'welcome', 'everyone'], ['reminder', 'holiday', 'party', 'next', 'friday', 'rsvp', 'wednesday'], ['quarterly', 'report', 'excellent', 'performance'], ['thanks', 'everyone', 'participating', 'wellness', 'program'], ['congratulation', 'tech', 'team', 'innovative', 'solution'], ['new', 'project', 'management', 'tool', 'live', 'check', 'email', 'detail'], ['new', 'cafeteria', 'menu', 'hit', 'great', 'choice', 'everyone'], ['company', 'picnic', 'huge', 'success', 'thanks', 'came'], ['reminder', 'annual', 'award', 'ceremony', 'next', 'month', 'submit', 'nomination'], ['great', 'feedback', 'recent', 'client', 'survey', 'keep'], ['printer', 'floor', 'toner'], ['wifi', 'floor', 'seems', 'looking'], ['elevator', 'east', 'wing', 'maintenance', 'today'], ['anyone', 'else', 'experiencing', 'issue', 'accessing', 'hr', 'portal'], ['office', 'gym', 'closed', 'renovation', 'starting', 'next', 'monday'], ['parking', 'lot', 'repaved', 'weekend', 'plan', 'accordingly'], ['holiday', 'schedule', 'next', 'year', 'posted', 'check', 'intranet', 'detail'], ['update', 'new', 'security', 'patch', 'deployed', 'tonight', 'expect', 'brief', 'downtime'], ['apology', 'confusion', 'earlier', 'here', 'corrected', 'budget', 'spreadsheet'], ['update', 'network', 'upgrade', 'scheduled', 'weekend', 'minimal', 'disruption', 'expected'], ['emergency', 'maintenance', 'building', 'today', 'expect', 'disruption'], ['ceo', 'visiting', 'office', 'next', 'week', 'let', 'ensure', 'everything', 'ready'], ['meeting', 'finance', 'team', 'postponed', 'thursday'], ['reminder', 'bring', 'id', 'badge', 'security', 'audit', 'tomorrow'], ['office', 'gym', 'closed', 'renovation', 'starting', 'next', 'monday'], ['please', 'remember', 'label', 'food', 'fridge', 'name', 'date'], ['reminder', 'parking', 'lot', 'repaved', 'weekend', 'plan', 'accordingly'], ['please', 'keep', 'kitchen', 'area', 'clean', 'tidy', 'report', 'issue', 'facility'], ['hr', 'update', 'new', 'parental', 'leave', 'policy', 'effect', 'detail', 'hr', 'portal'], ['apology', 'short', 'notice', 'meeting', 'canceled'], ['server', 'currently', 'working', 'resolve', 'issue'], ['reminder', 'fire', 'drill', 'scheduled', 'tomorrow'], ['received', 'complaint', 'noise', 'level', 'office', 'please', 'mindful'], ['client', 'meeting', 'rescheduled', 'next', 'week'], ['due', 'budget', 'cut', 'office', 'party', 'canceled'], ['reminder', 'performance', 'review', 'due', 'end', 'month'], ['air', 'conditioning', 'working', 'floor', 'facility', 'addressing'], ['reminder', 'submit', 'timesheets', 'end', 'day'], ['water', 'cooler', 'floor', 'order', 'facility', 'working'], ['due', 'unforeseen', 'circumstance', 'office', 'closed', 'tomorrow'], ['kitchen', 'undergoing', 'renovation', 'next', 'week'], ['quarterly', 'meeting', 'rescheduled', 'next', 'wednesday'], ['parking', 'garage', 'closed', 'maintenance', 'weekend'], ['company', 'internet', 'service', 'maintenance', 'tonight'], ['client', 'requested', 'revision', 'proposal', 'please', 'address', 'eod'], ['reminder', 'companywide', 'meeting', 'postponed'], ['office', 'heating', 'system', 'currently', 'repaired'], ['reminder', 'deadline', 'project', 'moved', 'friday'], ['report', 'phishing', 'email', 'please', 'cautious'], ['company', 'picnic', 'canceled', 'due', 'bad', 'weather'], ['building', 'water', 'supply', 'shut', 'maintenance', 'tomorrow'], ['reminder', 'annual', 'review', 'process', 'start', 'next', 'week'], ['cafeteria', 'closed', 'cleaning', 'friday'], ['power', 'building', 'pm', 'midnight', 'tonight'], ['office', 'security', 'system', 'upgraded', 'today'], ['client', 'expressed', 'dissatisfaction', 'current', 'project', 'status'], ['company', 'expense', 'policy', 'revised', 'check', 'email', 'detail'], ['reminder', 'office', 'closed', 'public', 'holiday'], ['new', 'software', 'caused', 'issue', 'user', 'investigating'], ['complaint', 'cleanliness', 'break', 'room', 'please', 'considerate'], ['client', 'presentation', 'moved', 'later', 'date'], ['reminder', 'companywide', 'survey', 'close', 'tomorrow'], ['hvac', 'system', 'serviced', 'weekend', 'expect', 'temperature', 'fluctuation'], ['building', 'exterior', 'painted', 'next', 'week', 'please', 'use', 'side', 'entrance'], ['report', 'unauthorized', 'access', 'attempt', 'change', 'password'], ['reminder', 'personal', 'belonging', 'must', 'removed', 'desk', 'friday'], ['company', 'data', 'protection', 'policy', 'updated', 'review', 'change'], ['client', 'unhappy', 'recent', 'deliverable', 'need', 'address', 'urgently'], ['office', 'pest', 'control', 'service', 'conducted', 'weekend'], ['reminder', 'update', 'emergency', 'contact', 'information', 'hr'], ['company', 'travel', 'policy', 'revised', 'check', 'email', 'detail'], ['new', 'project', 'delayed', 'due', 'unforeseen', 'issue'], ['reminder', 'company', 'annual', 'budget', 'meeting', 'next', 'monday'], ['client', 'feedback', 'recent', 'project', 'positive', 'need', 'improve'], ['office', 'parking', 'lot', 'repaved', 'next', 'month', 'plan', 'accordingly'], ['company', 'holiday', 'schedule', 'updated', 'check', 'email'], ['reminder', 'fire', 'alarm', 'system', 'tested', 'tomorrow'], ['client', 'requested', 'meeting', 'discus', 'concern'], ['company', 'internet', 'security', 'breached', 'addressing', 'issue'], ['office', 'air', 'quality', 'monitored', 'due', 'recent', 'complaint'], ['reminder', 'company', 'wellness', 'program', 'start', 'next', 'week'], ['client', 'raised', 'concern', 'project', 'timeline', 'need', 'reassess'], ['office', 'janitorial', 'service', 'schedule', 'updated', 'check', 'email'], ['anyone', 'seen', 'blue', 'notebook', 'think', 'left', 'meeting', 'room'], ['anyone', 'free', 'quick', 'coffee', 'catchup', 'afternoon'], ['quick', 'poll', 'team', 'lunch', 'option', 'friday', 'mexican', 'italian'], ['proposal', 'new', 'office', 'furniture', 'submitted', 'awaiting', 'approval'], ['reminder', 'companywide', 'webinar', 'market', 'trend', 'tomorrow', 'morning'], ['dont', 'forget', 'update', 'project', 'status', 'shared', 'drive'], ['office', 'garden', 'looking', 'great', 'thanks', 'volunteer'], ['holiday', 'schedule', 'next', 'year', 'posted', 'check', 'intranet', 'detail'], ['anyone', 'else', 'experiencing', 'issue', 'accessing', 'hr', 'portal'], ['new', 'cafeteria', 'menu', 'hit', 'great', 'choice', 'everyone'], ['reminder', 'office', 'potluck', 'tomorrow', 'dont', 'forget', 'bring', 'dish'], ['meeting', 'finance', 'team', 'postponed', 'thursday'], ['company', 'data', 'protection', 'policy', 'updated', 'review', 'change'], ['reminder', 'submit', 'timesheets', 'end', 'day'], ['cafeteria', 'closed', 'cleaning', 'friday'], ['quarterly', 'meeting', 'rescheduled', 'next', 'wednesday'], ['quick', 'update', 'elevator', 'east', 'wing', 'maintenance', 'today'], ['company', 'picnic', 'rescheduled', 'next', 'month', 'due', 'weather', 'forecast'], ['power', 'building', 'pm', 'midnight', 'tonight'], ['client', 'requested', 'revision', 'proposal', 'please', 'address', 'eod'], ['office', 'heating', 'system', 'currently', 'repaired'], ['sent', 'agenda', 'next', 'week', 'team', 'meeting', 'check', 'inbox'], ['reminder', 'update', 'emergency', 'contact', 'information', 'hr'], ['company', 'travel', 'policy', 'revised', 'check', 'email', 'detail'], ['new', 'cafeteria', 'menu', 'option', 'available', 'starting', 'next', 'week'], ['dont', 'forget', 'sign', 'company', 'picnic', 'next', 'weekend'], ['water', 'cooler', 'floor', 'order', 'facility', 'working'], ['office', 'pest', 'control', 'service', 'conducted', 'weekend'], ['parking', 'garage', 'closed', 'maintenance', 'weekend'], ['quick', 'update', 'hr', 'policy', 'change', 'announced', 'check', 'inbox', 'detail'], ['reminder', 'annual', 'company', 'retreat', 'registration', 'close', 'friday'], ['company', 'internet', 'service', 'maintenance', 'tonight'], ['reminder', 'fire', 'drill', 'scheduled', 'today', 'please', 'participate'], ['building', 'water', 'supply', 'shut', 'maintenance', 'tomorrow'], ['new', 'training', 'program', 'well', 'received'], ['reminder', 'annual', 'review', 'process', 'start', 'next', 'week'], ['client', 'presentation', 'moved', 'later', 'date'], ['company', 'picnic', 'huge', 'success', 'thanks', 'came'], ['reminder', 'company', 'wellness', 'program', 'start', 'next', 'week'], ['hvac', 'system', 'serviced', 'weekend', 'expect', 'temperature', 'fluctuation'], ['reminder', 'yoga', 'class', 'conference', 'room', 'pm'], ['office', 'security', 'system', 'upgraded', 'today'], ['reminder', 'companywide', 'meeting', 'postponed'], ['company', 'expense', 'policy', 'revised', 'check', 'email', 'detail'], ['updated', 'health', 'benefit', 'package', 'available', 'check', 'email', 'detail'], ['reminder', 'office', 'closed', 'public', 'holiday'], ['building', 'exterior', 'painted', 'next', 'week', 'please', 'use', 'side', 'entrance'], ['client', 'expressed', 'dissatisfaction', 'current', 'project', 'status'], ['reminder', 'office', 'closed', 'public', 'holiday'], ['company', 'holiday', 'schedule', 'updated', 'check', 'email'], ['reminder', 'personal', 'belonging', 'must', 'removed', 'desk', 'friday'], ['client', 'requested', 'meeting', 'discus', 'concern'], ['company', 'internet', 'security', 'breached', 'addressing', 'issue'], ['office', 'air', 'quality', 'monitored', 'due', 'recent', 'complaint'], ['reminder', 'flu', 'shot', 'available', 'break', 'room', 'today', 'pm', 'pm'], ['company', 'new', 'intern', 'program', 'start', 'next', 'week', 'welcome', 'everyone'], ['reminder', 'submit', 'project', 'update', 'end', 'day'], ['company', 'data', 'protection', 'policy', 'updated', 'review', 'change'], ['new', 'cafeteria', 'menu', 'option', 'available', 'starting', 'next', 'week'], ['company', 'internet', 'service', 'maintenance', 'tonight'], ['client', 'requested', 'revision', 'proposal', 'please', 'address', 'eod'], ['reminder', 'annual', 'company', 'retreat', 'registration', 'close', 'friday'], ['new', 'training', 'program', 'well', 'received'], ['company', 'picnic', 'huge', 'success', 'thanks', 'came'], ['reminder', 'company', 'wellness', 'program', 'start', 'next', 'week'], ['hvac', 'system', 'serviced', 'weekend', 'expect', 'temperature', 'fluctuation'], ['reminder', 'yoga', 'class', 'conference', 'room', 'pm'], ['office', 'security', 'system', 'upgraded', 'today'], ['reminder', 'companywide', 'meeting', 'postponed'], ['company', 'expense', 'policy', 'revised', 'check', 'email', 'detail'], ['updated', 'health', 'benefit', 'package', 'available', 'check', 'email', 'detail'], ['reminder', 'office', 'closed', 'public', 'holiday']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Vectore Embeddings ###\n",
        "vector_size = 20\n",
        "word2vec_model = get_word2vec_model(token_matrix, vector_size=vector_size)"
      ],
      "metadata": {
        "id": "Jttao6kkOsNQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Creating Input for Models ###\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(token_matrix_to_string_array(token_matrix))\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(token_matrix_to_string_array(token_matrix))\n",
        "max_length = max([len(seq) for seq in sequences])\n",
        "\n",
        "#create embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, vector_size))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix[i] = word2vec_model.wv[word]\n",
        "\n",
        "sentences_before, words_after = [], []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        sentences_before.append(seq[:i])\n",
        "        words_after.append(seq[i])\n",
        "\n",
        "sentences_before = pad_sequences(sentences_before, maxlen=max_length, padding='pre')\n",
        "words_after = np.array(words_after)\n",
        "\n",
        "sentences_before_train, sentences_before_test, words_after_train, words_after_test = train_test_split(sentences_before, words_after, test_size=0.2, random_state=42)\n",
        "sentences_before_train = np.array(sentences_before_train)\n",
        "sentences_before_test = np.array(sentences_before_test)\n",
        "words_after_train = np.array(words_after_train).reshape(-1)\n",
        "words_after_test = np.array(words_after_test).reshape(-1)"
      ],
      "metadata": {
        "id": "-n7RF_K3S1za"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define model\n",
        "rnn_model = get_recurrent_model(model_type='RNN', unit_num=128, vocab_size=vocab_size, vector_size=vector_size, max_length=max_length, embedding_matrix=embedding_matrix)\n",
        "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#train model\n",
        "rnn_model.fit(sentences_before_train, words_after_train, epochs=10, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL1nJsRwzBIm",
        "outputId": "5fff049e-b52e-4370-81f8-20a1d9b8ed22"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "986/986 [==============================] - 6s 5ms/step - loss: 5.9465 - accuracy: 0.0243\n",
            "Epoch 2/10\n",
            "986/986 [==============================] - 6s 6ms/step - loss: 5.3944 - accuracy: 0.0365\n",
            "Epoch 3/10\n",
            "986/986 [==============================] - 5s 5ms/step - loss: 5.0324 - accuracy: 0.0436\n",
            "Epoch 4/10\n",
            "986/986 [==============================] - 5s 5ms/step - loss: 4.8027 - accuracy: 0.0629\n",
            "Epoch 5/10\n",
            "986/986 [==============================] - 6s 6ms/step - loss: 4.6369 - accuracy: 0.0842\n",
            "Epoch 6/10\n",
            "986/986 [==============================] - 5s 5ms/step - loss: 4.4830 - accuracy: 0.0791\n",
            "Epoch 7/10\n",
            "986/986 [==============================] - 6s 6ms/step - loss: 4.3037 - accuracy: 0.0943\n",
            "Epoch 8/10\n",
            "986/986 [==============================] - 5s 5ms/step - loss: 4.0919 - accuracy: 0.1278\n",
            "Epoch 9/10\n",
            "986/986 [==============================] - 5s 5ms/step - loss: 3.8701 - accuracy: 0.1592\n",
            "Epoch 10/10\n",
            "986/986 [==============================] - 6s 6ms/step - loss: 3.6865 - accuracy: 0.1856\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78849923f070>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define model\n",
        "lstm_model = get_recurrent_model(model_type='LSTM', unit_num=128, vocab_size=vocab_size, vector_size=vector_size, max_length=max_length, embedding_matrix=embedding_matrix)\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#train model\n",
        "lstm_model.fit(sentences_before_train, words_after_train, epochs=10, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbeenvBezRdp",
        "outputId": "b01ad7dd-862f-4b1f-8119-a1a08fd0fa07"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "986/986 [==============================] - 12s 10ms/step - loss: 6.0036 - accuracy: 0.0172\n",
            "Epoch 2/10\n",
            "986/986 [==============================] - 10s 10ms/step - loss: 5.5702 - accuracy: 0.0284\n",
            "Epoch 3/10\n",
            "986/986 [==============================] - 10s 10ms/step - loss: 5.3133 - accuracy: 0.0416\n",
            "Epoch 4/10\n",
            "986/986 [==============================] - 11s 11ms/step - loss: 5.0770 - accuracy: 0.0497\n",
            "Epoch 5/10\n",
            "986/986 [==============================] - 9s 9ms/step - loss: 4.8282 - accuracy: 0.0527\n",
            "Epoch 6/10\n",
            "986/986 [==============================] - 10s 10ms/step - loss: 4.6048 - accuracy: 0.0680\n",
            "Epoch 7/10\n",
            "986/986 [==============================] - 10s 11ms/step - loss: 4.3895 - accuracy: 0.0842\n",
            "Epoch 8/10\n",
            "986/986 [==============================] - 11s 11ms/step - loss: 4.1621 - accuracy: 0.1055\n",
            "Epoch 9/10\n",
            "986/986 [==============================] - 9s 9ms/step - loss: 3.9561 - accuracy: 0.1227\n",
            "Epoch 10/10\n",
            "986/986 [==============================] - 10s 11ms/step - loss: 3.7641 - accuracy: 0.1531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78849b8355a0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate\n",
        "rnn_loss = rnn_model.evaluate(sentences_before_test, words_after_test, verbose=0)[0]\n",
        "rnn_perplexity = np.exp(rnn_loss)\n",
        "lstm_loss = lstm_model.evaluate(sentences_before_test, words_after_test, verbose=0)[0]\n",
        "lstm_perplexity = np.exp(lstm_loss)\n",
        "print(f'RNN loss={rnn_loss}, perplexity={rnn_perplexity}')\n",
        "print(f'LSTM loss={lstm_loss}, perplexity={lstm_perplexity}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubXoObydzRyB",
        "outputId": "f100d1e3-bf5e-4d3a-86ab-a13ce7fc6f65"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN loss=6.7658820152282715, perplexity=867.7312225152211\n",
            "LSTM loss=6.874927043914795, perplexity=967.7047630581189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### GPT-2 ###\n",
        "\n",
        "#define model\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "#generate completions for the sentences\n",
        "sentences = token_matrix_to_string_array([arr[:len(arr)//2] for arr in token_matrix[:4]])\n",
        "completions = [generate_completion(gpt_model, gpt_tokenizer, sentence) for sentence in sentences]\n",
        "\n",
        "print('\\n\\n')\n",
        "# Print the completions\n",
        "for i, (sentence, completion) in enumerate(zip(sentences, completions)):\n",
        "    print(f\"Original Sentence {i+1}: {sentence}\")\n",
        "    print(f\"Completion {i+1}: {completion}\\n\")\n",
        "    print('-----------------------------------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnlQS_LW3vxl",
        "outputId": "3ea6e0d3-e40e-46b5-bdb6-d130fcb8ad3a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Original Sentence 1: hey team quick reminder\n",
            "Completion 1: hey team quick reminder:\n",
            "\n",
            "The team is not responsible for any damage caused by the use of this product.\n",
            ".\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Original Sentence 2: anyone latest sale\n",
            "Completion 2: anyone latest sale.\n",
            "\n",
            "The company has been in the news recently for its controversial decision to sell its own mobile phone business to Google. The\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Original Sentence 3: happy friday\n",
            "Completion 3: happy friday, and I'm going to be back in the studio with you guys.\n",
            "\n",
            "I'm gonna be in a lot of different places\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Original Sentence 4: congrats marketing team\n",
            "Completion 4: congrats marketing team.\n",
            "\n",
            "\"We're excited to be working with you on this project,\" said the company's CEO, John D. D\n",
            "\n",
            "-----------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentiment Analysis ###\n",
        "texts = messages_df['Messages'].tolist()\n",
        "labels = messages_df['Sentiment'].tolist()\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "x_data = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoded_labels = encoder.fit_transform(labels)\n",
        "encoded_labels = tf.keras.utils.to_categorical(encoded_labels)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, encoded_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "X9CVHZK0IFQ4"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=vector_size, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(len(set(labels)), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y7ihl8VI4b3",
        "outputId": "946a1d11-b7dc-4aec-c00a-ece5975f8b7e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 10, 20)            8880      \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 128)               76288     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85555 (334.20 KB)\n",
            "Trainable params: 76675 (299.51 KB)\n",
            "Non-trainable params: 8880 (34.69 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "model.fit(x_train, y_train, batch_size=10, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx3-d_1iK9Ou",
        "outputId": "ab005318-c480-440e-ab10-ca71a87e27e0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.9406 - accuracy: 0.5307 - val_loss: 0.9724 - val_accuracy: 0.5111\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.9395 - accuracy: 0.5307 - val_loss: 0.9711 - val_accuracy: 0.4889\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.9279 - accuracy: 0.5251 - val_loss: 0.9692 - val_accuracy: 0.4889\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.9223 - accuracy: 0.5475 - val_loss: 0.9607 - val_accuracy: 0.4889\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.9364 - accuracy: 0.5251 - val_loss: 0.9620 - val_accuracy: 0.4889\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.9342 - accuracy: 0.5363 - val_loss: 0.9608 - val_accuracy: 0.5111\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.9227 - accuracy: 0.5363 - val_loss: 0.9560 - val_accuracy: 0.5111\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.9188 - accuracy: 0.5419 - val_loss: 0.9576 - val_accuracy: 0.4889\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.9012 - accuracy: 0.5698 - val_loss: 0.9606 - val_accuracy: 0.4889\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.9294 - accuracy: 0.5028 - val_loss: 0.9649 - val_accuracy: 0.4889\n"
          ]
        }
      ]
    }
  ]
}